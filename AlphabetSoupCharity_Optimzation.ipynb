{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13cb713-131a-4a35-bd86-f0b7257d2ab6",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e592d0-01d4-4303-87a7-ad9e97133a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2815f74-a870-46f8-8607-ed307a7e6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f5ba7de-6e47-4b76-99bb-0256e48f4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns = ['EIN', 'NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4369d2f4-b5de-4794-84f8-81e791da34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_type_bins = application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e193d605-0dea-433d-bedc-a93ef3b15084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "#  YOUR CODE GOES HERE\n",
    "\n",
    "#################### Changing bins to include values with over 100 occurrences instead of 500 ####################\n",
    "application_types_to_replace = []\n",
    "cutoff_val = 100\n",
    "for index, val in application_type_bins.items():\n",
    "    if val <= cutoff_val:\n",
    "        application_types_to_replace.append(index)\n",
    "        \n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5107f3eb-b67f-46c1-bd3d-2205c6e4e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_bins = application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2962e6-1916-436d-bf17-864892147954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "\n",
    "#################### Changing bins to include values with over 700 occurrences instead of 1000 ####################\n",
    "classifications_to_replace = []\n",
    "cutoff_val = 700\n",
    "for index, val in classification_bins.items():\n",
    "    if val <= cutoff_val:\n",
    "        classifications_to_replace.append(index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82089139-e9d5-43c7-adc7-574d17016d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "dummies_appilcation_df = pd.get_dummies(application_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bd3d73-aff1-4293-b178-b2e808de1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = dummies_appilcation_df.IS_SUCCESSFUL.values\n",
    "X = dummies_appilcation_df.drop(columns = 'IS_SUCCESSFUL').values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f55c8e-b316-4bd9-974e-176ad47d7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8526bff-0766-492a-a825-4571f574dba2",
   "metadata": {},
   "source": [
    "## Optimization #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c53f781-dd67-4286-afb4-cf27d70e1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 368       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 521\n",
      "Trainable params: 521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "######################## Remove some units per layer, add a hidden layer, and change activation to tanh #####################################\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=8, activation=\"tanh\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=8, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=8, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1e82fc-7a64-46d2-b979-def324bae2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca76249-44c8-4781-b891-d4e04ce498b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "804/804 [==============================] - 3s 2ms/step - loss: 0.5853 - accuracy: 0.7105\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5620 - accuracy: 0.7271\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5573 - accuracy: 0.7288\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5550 - accuracy: 0.7280\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5534 - accuracy: 0.7280\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5522 - accuracy: 0.7282\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5514 - accuracy: 0.7289\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.7299\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7296\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5494 - accuracy: 0.7311\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.7308\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7318\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7324\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7320\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7329\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.7333\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7323\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7324\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7326\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7323\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7319\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7318\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7334\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7324\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7334\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7333\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7335\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7331\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7331\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7328\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7337\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7334\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7331\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7339\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7338\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7330\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7337\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7333\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7339\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7336\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7325\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7338\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7336: 0s - los\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7343\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7349\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7339\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7341\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7349\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7344\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7339\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ffcb142-b869-470f-9ed7-4a8951dc8061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5516 - accuracy: 0.7289\n",
      "Loss: 0.5515550971031189, Accuracy: 0.728863000869751\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8981c66-0e26-48b2-9b5d-d91747b36c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Slightly better than our attempt before optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335337a-af62-4d62-bd3f-cec79d724d6a",
   "metadata": {},
   "source": [
    "## Optimization #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc47f912-4f53-4e02-99e7-e4abc58a38c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 24)                1104      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,793\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "######################## Add some units per layer, add a hidden layer, and change activation to relu #####################################\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"relu\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f82f5392-92ea-4ea7-9d06-73f62a2b0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e371ba2d-7064-43e1-bd81-0b56dc07f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5866 - accuracy: 0.7011\n",
      "Epoch 2/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5563 - accuracy: 0.7267: 0s - loss: 0.5549 - accu\n",
      "Epoch 3/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5523 - accuracy: 0.7281\n",
      "Epoch 4/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5508 - accuracy: 0.7291\n",
      "Epoch 5/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5496 - accuracy: 0.7296\n",
      "Epoch 6/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7309\n",
      "Epoch 7/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7315\n",
      "Epoch 8/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7315\n",
      "Epoch 9/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7331\n",
      "Epoch 10/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7328\n",
      "Epoch 11/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7323\n",
      "Epoch 12/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7325\n",
      "Epoch 13/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7324\n",
      "Epoch 14/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7332\n",
      "Epoch 15/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7342\n",
      "Epoch 16/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7323\n",
      "Epoch 17/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7341\n",
      "Epoch 18/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7348\n",
      "Epoch 19/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7340\n",
      "Epoch 20/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7339\n",
      "Epoch 21/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7338\n",
      "Epoch 22/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7341\n",
      "Epoch 23/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7347\n",
      "Epoch 24/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7339\n",
      "Epoch 25/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7351\n",
      "Epoch 26/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7339\n",
      "Epoch 27/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7343\n",
      "Epoch 28/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7343\n",
      "Epoch 29/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5412 - accuracy: 0.7345\n",
      "Epoch 30/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7346\n",
      "Epoch 31/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7352\n",
      "Epoch 32/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5407 - accuracy: 0.7355\n",
      "Epoch 33/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7355\n",
      "Epoch 34/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7360\n",
      "Epoch 35/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7352\n",
      "Epoch 36/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7354\n",
      "Epoch 37/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7368\n",
      "Epoch 38/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.7358\n",
      "Epoch 39/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.7355\n",
      "Epoch 40/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7361\n",
      "Epoch 41/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7359\n",
      "Epoch 42/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5391 - accuracy: 0.7353\n",
      "Epoch 43/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7358\n",
      "Epoch 44/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5391 - accuracy: 0.7372\n",
      "Epoch 45/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7371\n",
      "Epoch 46/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7365\n",
      "Epoch 47/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7364\n",
      "Epoch 48/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7374\n",
      "Epoch 49/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7370\n",
      "Epoch 50/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7368\n",
      "Epoch 51/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7361\n",
      "Epoch 52/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7372\n",
      "Epoch 53/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7369\n",
      "Epoch 54/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.7364\n",
      "Epoch 55/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7360\n",
      "Epoch 56/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7368\n",
      "Epoch 57/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7366\n",
      "Epoch 58/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.7369\n",
      "Epoch 59/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7381\n",
      "Epoch 60/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7363\n",
      "Epoch 61/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7375\n",
      "Epoch 62/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7384\n",
      "Epoch 63/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7376\n",
      "Epoch 64/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7376\n",
      "Epoch 65/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7374\n",
      "Epoch 66/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7373\n",
      "Epoch 67/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7386\n",
      "Epoch 68/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7375\n",
      "Epoch 69/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7379\n",
      "Epoch 70/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7389: 0s - loss: 0.5388 \n",
      "Epoch 71/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7376\n",
      "Epoch 72/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7379\n",
      "Epoch 73/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7383\n",
      "Epoch 74/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7376\n",
      "Epoch 75/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7378\n",
      "Epoch 76/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7378\n",
      "Epoch 77/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7379\n",
      "Epoch 78/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7383\n",
      "Epoch 79/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7377\n",
      "Epoch 80/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7378\n",
      "Epoch 81/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7385\n",
      "Epoch 82/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7382\n",
      "Epoch 83/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7372\n",
      "Epoch 84/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7380\n",
      "Epoch 85/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7376\n",
      "Epoch 86/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7384\n",
      "Epoch 87/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7383\n",
      "Epoch 88/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7388\n",
      "Epoch 89/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7389\n",
      "Epoch 90/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7391\n",
      "Epoch 91/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7387\n",
      "Epoch 92/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7382\n",
      "Epoch 93/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7385\n",
      "Epoch 94/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7381\n",
      "Epoch 95/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7385\n",
      "Epoch 96/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7397\n",
      "Epoch 97/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7393\n",
      "Epoch 98/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7380\n",
      "Epoch 99/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7396\n",
      "Epoch 100/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7389\n",
      "Epoch 101/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7400\n",
      "Epoch 102/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7387\n",
      "Epoch 103/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7388\n",
      "Epoch 104/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7390\n",
      "Epoch 105/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7394\n",
      "Epoch 106/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7386\n",
      "Epoch 107/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7392\n",
      "Epoch 108/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7392\n",
      "Epoch 109/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7392\n",
      "Epoch 110/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7387\n",
      "Epoch 111/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7387\n",
      "Epoch 112/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7390\n",
      "Epoch 113/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7396\n",
      "Epoch 114/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7399\n",
      "Epoch 115/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7390\n",
      "Epoch 116/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7389\n",
      "Epoch 117/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7393\n",
      "Epoch 118/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7395\n",
      "Epoch 119/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7394\n",
      "Epoch 120/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7395\n",
      "Epoch 121/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7393\n",
      "Epoch 122/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7388\n",
      "Epoch 123/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7386\n",
      "Epoch 124/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7400\n",
      "Epoch 125/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7395\n",
      "Epoch 126/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7401\n",
      "Epoch 127/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7403\n",
      "Epoch 128/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7384\n",
      "Epoch 129/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7393\n",
      "Epoch 130/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7399\n",
      "Epoch 131/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7396\n",
      "Epoch 132/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7399\n",
      "Epoch 133/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7396\n",
      "Epoch 134/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7397\n",
      "Epoch 135/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7399\n",
      "Epoch 136/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7393\n",
      "Epoch 137/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7394\n",
      "Epoch 138/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7391\n",
      "Epoch 139/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7402\n",
      "Epoch 140/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7402\n",
      "Epoch 141/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7392\n",
      "Epoch 142/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7389\n",
      "Epoch 143/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7400\n",
      "Epoch 144/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7397\n",
      "Epoch 145/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7399\n",
      "Epoch 146/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7398\n",
      "Epoch 147/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7403\n",
      "Epoch 148/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7405\n",
      "Epoch 149/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7392\n",
      "Epoch 150/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7399\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5ad0256-2cde-477c-b075-7ee6259e2f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5578 - accuracy: 0.7301\n",
      "Loss: 0.5578224062919617, Accuracy: 0.7301457524299622\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6346232f-f0de-495e-8a0d-5feec87b1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A little better, but not by much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafba8f-8b51-42eb-b035-d85ef17fce78",
   "metadata": {},
   "source": [
    "## Optimization #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d6fb167-0ebd-4d50-a9a0-a5827d9eb38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 30)                1380      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 24)                744       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 3,349\n",
      "Trainable params: 3,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "######################## Add some units per layer, add a hidden layer, and change activation to relu #####################################\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=30, activation=\"tanh\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd6b7fe9-5a0c-411a-bfb3-37af6e9af7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6eca48b3-5e24-44cc-975b-966faf7e0e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "804/804 [==============================] - 3s 2ms/step - loss: 0.5763 - accuracy: 0.7116\n",
      "Epoch 2/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5541 - accuracy: 0.7293\n",
      "Epoch 3/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7300\n",
      "Epoch 4/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5501 - accuracy: 0.7312\n",
      "Epoch 5/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5486 - accuracy: 0.7305\n",
      "Epoch 6/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7320\n",
      "Epoch 7/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7327\n",
      "Epoch 8/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7317\n",
      "Epoch 9/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7343\n",
      "Epoch 10/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7329\n",
      "Epoch 11/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7346\n",
      "Epoch 12/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7348\n",
      "Epoch 13/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7338\n",
      "Epoch 14/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7355\n",
      "Epoch 15/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7360\n",
      "Epoch 16/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7346\n",
      "Epoch 17/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7357\n",
      "Epoch 18/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7355\n",
      "Epoch 19/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7370\n",
      "Epoch 20/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7368\n",
      "Epoch 21/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.7371\n",
      "Epoch 22/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.7365\n",
      "Epoch 23/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5396 - accuracy: 0.7363\n",
      "Epoch 24/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7373\n",
      "Epoch 25/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7375\n",
      "Epoch 26/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7381\n",
      "Epoch 27/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7379\n",
      "Epoch 28/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7381\n",
      "Epoch 29/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7375\n",
      "Epoch 30/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.7383\n",
      "Epoch 31/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.7377\n",
      "Epoch 32/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7383\n",
      "Epoch 33/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.7381\n",
      "Epoch 34/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7384\n",
      "Epoch 35/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7385\n",
      "Epoch 36/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7384\n",
      "Epoch 37/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7383\n",
      "Epoch 38/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7389\n",
      "Epoch 39/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7383\n",
      "Epoch 40/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7377\n",
      "Epoch 41/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7392\n",
      "Epoch 42/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7387\n",
      "Epoch 43/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7397\n",
      "Epoch 44/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7393\n",
      "Epoch 45/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7387\n",
      "Epoch 46/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7394\n",
      "Epoch 47/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7388\n",
      "Epoch 48/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7393\n",
      "Epoch 49/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7395\n",
      "Epoch 50/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7398\n",
      "Epoch 51/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7386\n",
      "Epoch 52/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7400\n",
      "Epoch 53/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7397\n",
      "Epoch 54/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7395\n",
      "Epoch 55/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7393\n",
      "Epoch 56/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7389\n",
      "Epoch 57/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7393: 0s - loss: 0.5329 - accu\n",
      "Epoch 58/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7405\n",
      "Epoch 59/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7391\n",
      "Epoch 60/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7393\n",
      "Epoch 61/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7394\n",
      "Epoch 62/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7390\n",
      "Epoch 63/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7392\n",
      "Epoch 64/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7397\n",
      "Epoch 65/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7401\n",
      "Epoch 66/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7400\n",
      "Epoch 67/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7398\n",
      "Epoch 68/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7397\n",
      "Epoch 69/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7396\n",
      "Epoch 70/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7402\n",
      "Epoch 71/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7399\n",
      "Epoch 72/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7388\n",
      "Epoch 73/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7400\n",
      "Epoch 74/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7398\n",
      "Epoch 75/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7398\n",
      "Epoch 76/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7406\n",
      "Epoch 77/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7396\n",
      "Epoch 78/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7398\n",
      "Epoch 79/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7405\n",
      "Epoch 80/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7403\n",
      "Epoch 81/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7404\n",
      "Epoch 82/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7401\n",
      "Epoch 83/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7402\n",
      "Epoch 84/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7405\n",
      "Epoch 85/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7407\n",
      "Epoch 86/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7407\n",
      "Epoch 87/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7404\n",
      "Epoch 88/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7407\n",
      "Epoch 89/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7401\n",
      "Epoch 90/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7402\n",
      "Epoch 91/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7407\n",
      "Epoch 92/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7405\n",
      "Epoch 93/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7407\n",
      "Epoch 94/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7408\n",
      "Epoch 95/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7403\n",
      "Epoch 96/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7411\n",
      "Epoch 97/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7413\n",
      "Epoch 98/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7405\n",
      "Epoch 99/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7403\n",
      "Epoch 100/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7408\n",
      "Epoch 101/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7408\n",
      "Epoch 102/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7413\n",
      "Epoch 103/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.7413\n",
      "Epoch 104/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7404\n",
      "Epoch 105/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7412\n",
      "Epoch 106/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7404\n",
      "Epoch 107/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7407\n",
      "Epoch 108/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7420\n",
      "Epoch 109/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7408\n",
      "Epoch 110/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.7418\n",
      "Epoch 111/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7406\n",
      "Epoch 112/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7410\n",
      "Epoch 113/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7413\n",
      "Epoch 114/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7416\n",
      "Epoch 115/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7411\n",
      "Epoch 116/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7409\n",
      "Epoch 117/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7411\n",
      "Epoch 118/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7405\n",
      "Epoch 119/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7409\n",
      "Epoch 120/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7413\n",
      "Epoch 121/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7416\n",
      "Epoch 122/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7407\n",
      "Epoch 123/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7410: 0s - loss: 0.5319 - accuracy: \n",
      "Epoch 124/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7411\n",
      "Epoch 125/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7409\n",
      "Epoch 126/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7416\n",
      "Epoch 127/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7409\n",
      "Epoch 128/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7409\n",
      "Epoch 129/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7416\n",
      "Epoch 130/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7408\n",
      "Epoch 131/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7414\n",
      "Epoch 132/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7414\n",
      "Epoch 133/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7414\n",
      "Epoch 134/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7411\n",
      "Epoch 135/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7405\n",
      "Epoch 136/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7418\n",
      "Epoch 137/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7414\n",
      "Epoch 138/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7413\n",
      "Epoch 139/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7413\n",
      "Epoch 140/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7415\n",
      "Epoch 141/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7408\n",
      "Epoch 142/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7414\n",
      "Epoch 143/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7415\n",
      "Epoch 144/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7418\n",
      "Epoch 145/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7415\n",
      "Epoch 146/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7417\n",
      "Epoch 147/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7416\n",
      "Epoch 148/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7418: 0s - loss: 0.529\n",
      "Epoch 149/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7413\n",
      "Epoch 150/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7416\n",
      "Epoch 151/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7413\n",
      "Epoch 152/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7420: \n",
      "Epoch 153/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7414\n",
      "Epoch 154/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7425\n",
      "Epoch 155/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7412\n",
      "Epoch 156/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7411\n",
      "Epoch 157/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7410\n",
      "Epoch 158/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7415\n",
      "Epoch 159/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7417\n",
      "Epoch 160/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7417\n",
      "Epoch 161/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7419\n",
      "Epoch 162/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7424\n",
      "Epoch 163/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7413\n",
      "Epoch 164/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7419\n",
      "Epoch 165/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7419\n",
      "Epoch 166/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7421\n",
      "Epoch 167/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7405\n",
      "Epoch 168/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7414\n",
      "Epoch 169/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7418\n",
      "Epoch 170/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7423\n",
      "Epoch 171/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7414\n",
      "Epoch 172/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7416\n",
      "Epoch 173/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7422\n",
      "Epoch 174/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7415\n",
      "Epoch 175/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7417\n",
      "Epoch 176/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7412\n",
      "Epoch 177/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7409\n",
      "Epoch 178/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7427\n",
      "Epoch 179/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7416\n",
      "Epoch 180/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7421\n",
      "Epoch 181/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7420\n",
      "Epoch 182/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7421\n",
      "Epoch 183/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7420\n",
      "Epoch 184/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7414\n",
      "Epoch 185/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7423\n",
      "Epoch 186/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7411\n",
      "Epoch 187/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7421\n",
      "Epoch 188/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7419\n",
      "Epoch 189/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.7430\n",
      "Epoch 190/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7425\n",
      "Epoch 191/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7419\n",
      "Epoch 192/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7418\n",
      "Epoch 193/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7424\n",
      "Epoch 194/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7416\n",
      "Epoch 195/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7423\n",
      "Epoch 196/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7420\n",
      "Epoch 197/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7425\n",
      "Epoch 198/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7423\n",
      "Epoch 199/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7413\n",
      "Epoch 200/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7425\n",
      "Epoch 201/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7418\n",
      "Epoch 202/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7414\n",
      "Epoch 203/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7420\n",
      "Epoch 204/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7419\n",
      "Epoch 205/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7420\n",
      "Epoch 206/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7420\n",
      "Epoch 207/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7418\n",
      "Epoch 208/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7425\n",
      "Epoch 209/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7418\n",
      "Epoch 210/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7414\n",
      "Epoch 211/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7421\n",
      "Epoch 212/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7420\n",
      "Epoch 213/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7418\n",
      "Epoch 214/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7421\n",
      "Epoch 215/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7419\n",
      "Epoch 216/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7422\n",
      "Epoch 217/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7418\n",
      "Epoch 218/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7424\n",
      "Epoch 219/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7422\n",
      "Epoch 220/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7421\n",
      "Epoch 221/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7424\n",
      "Epoch 222/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7421\n",
      "Epoch 223/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7421\n",
      "Epoch 224/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7427\n",
      "Epoch 225/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7420\n",
      "Epoch 226/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7423\n",
      "Epoch 227/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7418\n",
      "Epoch 228/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7423\n",
      "Epoch 229/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7410\n",
      "Epoch 230/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7422\n",
      "Epoch 231/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7416\n",
      "Epoch 232/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7420\n",
      "Epoch 233/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7414\n",
      "Epoch 234/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7414\n",
      "Epoch 235/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5286 - accuracy: 0.7423\n",
      "Epoch 236/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7422\n",
      "Epoch 237/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7421\n",
      "Epoch 238/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7422\n",
      "Epoch 239/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5286 - accuracy: 0.7423\n",
      "Epoch 240/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5286 - accuracy: 0.7422\n",
      "Epoch 241/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5286 - accuracy: 0.7417\n",
      "Epoch 242/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7416\n",
      "Epoch 243/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7424\n",
      "Epoch 244/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7416\n",
      "Epoch 245/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5283 - accuracy: 0.7422\n",
      "Epoch 246/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7423\n",
      "Epoch 247/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5285 - accuracy: 0.7414\n",
      "Epoch 248/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7411\n",
      "Epoch 249/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7430\n",
      "Epoch 250/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5284 - accuracy: 0.7429\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf16d3d4-2e7d-42d4-9057-759fa64f6b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5853 - accuracy: 0.7289\n",
      "Loss: 0.5852657556533813, Accuracy: 0.728863000869751\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2333e048-b9ec-4c26-a049-a017d3301a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not sure where this accuracy test is getting its accuracy from but the epochs managed a steady 74.2% accuracy which is a little better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e853e9d7-ac2d-49f5-965e-575b150855d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cc15647-fbac-48ab-a0b8-e2b7e7bdda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save('Models/alphabetSoupCharity_Optimization.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb46dee-66fc-42c4-a0f8-6d69a41a5d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
