{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13cb713-131a-4a35-bd86-f0b7257d2ab6",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e592d0-01d4-4303-87a7-ad9e97133a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2815f74-a870-46f8-8607-ed307a7e6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f5ba7de-6e47-4b76-99bb-0256e48f4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns = ['EIN', 'NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4369d2f4-b5de-4794-84f8-81e791da34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_type_bins = application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e193d605-0dea-433d-bedc-a93ef3b15084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "#  YOUR CODE GOES HERE\n",
    "\n",
    "#################### Changing bins to include values with over 100 occurrences instead of 500 ####################\n",
    "application_types_to_replace = []\n",
    "cutoff_val = 100\n",
    "for index, val in application_type_bins.items():\n",
    "    if val <= cutoff_val:\n",
    "        application_types_to_replace.append(index)\n",
    "        \n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5107f3eb-b67f-46c1-bd3d-2205c6e4e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_bins = application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2962e6-1916-436d-bf17-864892147954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "\n",
    "#################### Changing bins to include values with over 700 occurrences instead of 1000 ####################\n",
    "classifications_to_replace = []\n",
    "cutoff_val = 700\n",
    "for index, val in classification_bins.items():\n",
    "    if val <= cutoff_val:\n",
    "        classifications_to_replace.append(index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82089139-e9d5-43c7-adc7-574d17016d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "dummies_appilcation_df = pd.get_dummies(application_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bd3d73-aff1-4293-b178-b2e808de1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = dummies_appilcation_df.IS_SUCCESSFUL.values\n",
    "X = dummies_appilcation_df.drop(columns = 'IS_SUCCESSFUL').values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f55c8e-b316-4bd9-974e-176ad47d7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8526bff-0766-492a-a825-4571f574dba2",
   "metadata": {},
   "source": [
    "## Optimization #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c53f781-dd67-4286-afb4-cf27d70e1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 368       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 521\n",
      "Trainable params: 521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "######################## Remove some units per layer, add a hidden layer, and change activation to tanh #####################################\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=8, activation=\"tanh\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=8, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=8, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1e82fc-7a64-46d2-b979-def324bae2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca76249-44c8-4781-b891-d4e04ce498b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5997 - accuracy: 0.6906\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7260\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5572 - accuracy: 0.7287\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5552 - accuracy: 0.7299\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5538 - accuracy: 0.7310\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5522 - accuracy: 0.7312\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5514 - accuracy: 0.7307\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.7313\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7316\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7320\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7322\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5479 - accuracy: 0.7323\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7325\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7327\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7323\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7331\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7327\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7327\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7326\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7338\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7326\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7339\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7332\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7335\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7333\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7333\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7336\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7341\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7337\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7336: 0s -\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7334\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7341\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7341\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7349\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7344\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7336\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7345\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7341\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7354\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7352\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7351\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7348\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7351\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7350\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7345\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7349\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7353\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7355\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7351\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7356\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ffcb142-b869-470f-9ed7-4a8951dc8061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5530 - accuracy: 0.7322\n",
      "Loss: 0.5530444979667664, Accuracy: 0.7322449088096619\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8981c66-0e26-48b2-9b5d-d91747b36c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Slightly better than our attempt before optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335337a-af62-4d62-bd3f-cec79d724d6a",
   "metadata": {},
   "source": [
    "## Optimization #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc47f912-4f53-4e02-99e7-e4abc58a38c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 24)                1104      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,793\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "######################## Add some units per layer, add a hidden layer, and change activation to relu #####################################\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"relu\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"tanh\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f82f5392-92ea-4ea7-9d06-73f62a2b0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e371ba2d-7064-43e1-bd81-0b56dc07f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.6336 - accuracy: 0.7031\n",
      "Epoch 2/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5985 - accuracy: 0.7115\n",
      "Epoch 3/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5693 - accuracy: 0.7274\n",
      "Epoch 4/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5659 - accuracy: 0.7277\n",
      "Epoch 5/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5754 - accuracy: 0.7255\n",
      "Epoch 6/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5646 - accuracy: 0.7299\n",
      "Epoch 7/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5818 - accuracy: 0.7243\n",
      "Epoch 8/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5694 - accuracy: 0.7279\n",
      "Epoch 9/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5651 - accuracy: 0.7299\n",
      "Epoch 10/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5622 - accuracy: 0.7308\n",
      "Epoch 11/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5625 - accuracy: 0.7303\n",
      "Epoch 12/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5641 - accuracy: 0.7298\n",
      "Epoch 13/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5636 - accuracy: 0.7301\n",
      "Epoch 14/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5597 - accuracy: 0.7321\n",
      "Epoch 15/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5590 - accuracy: 0.7322\n",
      "Epoch 16/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5644 - accuracy: 0.7317\n",
      "Epoch 17/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5576 - accuracy: 0.7322\n",
      "Epoch 18/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5565 - accuracy: 0.7329\n",
      "Epoch 19/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5787 - accuracy: 0.7261\n",
      "Epoch 20/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5649 - accuracy: 0.7293\n",
      "Epoch 21/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5590 - accuracy: 0.7322\n",
      "Epoch 22/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5565 - accuracy: 0.7332\n",
      "Epoch 23/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5604 - accuracy: 0.7335\n",
      "Epoch 24/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5606 - accuracy: 0.7335\n",
      "Epoch 25/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5580 - accuracy: 0.7337\n",
      "Epoch 26/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5557 - accuracy: 0.7355\n",
      "Epoch 27/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5553 - accuracy: 0.7325\n",
      "Epoch 28/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5540 - accuracy: 0.7337\n",
      "Epoch 29/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5532 - accuracy: 0.7343\n",
      "Epoch 30/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5592 - accuracy: 0.7336\n",
      "Epoch 31/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5588 - accuracy: 0.7341\n",
      "Epoch 32/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5601 - accuracy: 0.7339\n",
      "Epoch 33/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5583 - accuracy: 0.7330\n",
      "Epoch 34/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5601 - accuracy: 0.7339\n",
      "Epoch 35/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5594 - accuracy: 0.7335\n",
      "Epoch 36/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5629 - accuracy: 0.7318\n",
      "Epoch 37/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5602 - accuracy: 0.7342\n",
      "Epoch 38/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5592 - accuracy: 0.7339\n",
      "Epoch 39/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5589 - accuracy: 0.7336\n",
      "Epoch 40/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5591 - accuracy: 0.7325\n",
      "Epoch 41/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5534 - accuracy: 0.7346\n",
      "Epoch 42/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5557 - accuracy: 0.7354\n",
      "Epoch 43/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5564 - accuracy: 0.7338\n",
      "Epoch 44/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5564 - accuracy: 0.7346\n",
      "Epoch 45/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5519 - accuracy: 0.7338\n",
      "Epoch 46/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5524 - accuracy: 0.7329\n",
      "Epoch 47/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5516 - accuracy: 0.7361\n",
      "Epoch 48/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5528 - accuracy: 0.7340\n",
      "Epoch 49/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5541 - accuracy: 0.7343\n",
      "Epoch 50/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5547 - accuracy: 0.7350\n",
      "Epoch 51/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5561 - accuracy: 0.7353\n",
      "Epoch 52/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5569 - accuracy: 0.7336\n",
      "Epoch 53/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5511 - accuracy: 0.7361\n",
      "Epoch 54/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5537 - accuracy: 0.7339\n",
      "Epoch 55/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.7357\n",
      "Epoch 56/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5543 - accuracy: 0.7338\n",
      "Epoch 57/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5507 - accuracy: 0.7352\n",
      "Epoch 58/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5529 - accuracy: 0.7357\n",
      "Epoch 59/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7349\n",
      "Epoch 60/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5524 - accuracy: 0.7348\n",
      "Epoch 61/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.7346\n",
      "Epoch 62/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7362\n",
      "Epoch 63/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7349\n",
      "Epoch 64/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7364\n",
      "Epoch 65/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7371\n",
      "Epoch 66/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7337\n",
      "Epoch 67/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7352\n",
      "Epoch 68/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7360\n",
      "Epoch 69/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7362\n",
      "Epoch 70/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5501 - accuracy: 0.7361\n",
      "Epoch 71/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7350\n",
      "Epoch 72/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5420 - accuracy: 0.7361\n",
      "Epoch 73/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7356\n",
      "Epoch 74/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7362\n",
      "Epoch 75/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7366\n",
      "Epoch 76/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7368\n",
      "Epoch 77/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7357\n",
      "Epoch 78/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7358\n",
      "Epoch 79/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7364\n",
      "Epoch 80/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7370\n",
      "Epoch 81/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7372\n",
      "Epoch 82/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7370\n",
      "Epoch 83/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7376\n",
      "Epoch 84/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7378\n",
      "Epoch 85/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7360\n",
      "Epoch 86/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7368\n",
      "Epoch 87/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7362\n",
      "Epoch 88/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7373\n",
      "Epoch 89/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7361\n",
      "Epoch 90/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7361\n",
      "Epoch 91/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7374\n",
      "Epoch 92/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7375\n",
      "Epoch 93/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7371\n",
      "Epoch 94/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7374\n",
      "Epoch 95/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7381\n",
      "Epoch 96/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7381\n",
      "Epoch 97/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7356\n",
      "Epoch 98/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7368\n",
      "Epoch 99/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7360\n",
      "Epoch 100/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7367\n",
      "Epoch 101/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7369\n",
      "Epoch 102/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7369\n",
      "Epoch 103/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7369\n",
      "Epoch 104/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7374\n",
      "Epoch 105/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7372\n",
      "Epoch 106/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7371\n",
      "Epoch 107/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7381\n",
      "Epoch 108/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7372\n",
      "Epoch 109/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7384\n",
      "Epoch 110/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7370\n",
      "Epoch 111/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7367\n",
      "Epoch 112/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7380\n",
      "Epoch 113/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7379\n",
      "Epoch 114/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7368\n",
      "Epoch 115/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7374\n",
      "Epoch 116/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7363\n",
      "Epoch 117/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.7369\n",
      "Epoch 118/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7380\n",
      "Epoch 119/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7382\n",
      "Epoch 120/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7379\n",
      "Epoch 121/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7374\n",
      "Epoch 122/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7381\n",
      "Epoch 123/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7370\n",
      "Epoch 124/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7379\n",
      "Epoch 125/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7387\n",
      "Epoch 126/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7383: 0s - loss: 0.5431 \n",
      "Epoch 127/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7378\n",
      "Epoch 128/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5514 - accuracy: 0.7371\n",
      "Epoch 129/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7376\n",
      "Epoch 130/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7381\n",
      "Epoch 131/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7393\n",
      "Epoch 132/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7379\n",
      "Epoch 133/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5453 - accuracy: 0.7369\n",
      "Epoch 134/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.7365\n",
      "Epoch 135/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7397\n",
      "Epoch 136/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7383\n",
      "Epoch 137/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.7379\n",
      "Epoch 138/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7378\n",
      "Epoch 139/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7373\n",
      "Epoch 140/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7380\n",
      "Epoch 141/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7382\n",
      "Epoch 142/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7373\n",
      "Epoch 143/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7387\n",
      "Epoch 144/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7387\n",
      "Epoch 145/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5431 - accuracy: 0.7382\n",
      "Epoch 146/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7376\n",
      "Epoch 147/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7382\n",
      "Epoch 148/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7385\n",
      "Epoch 149/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7378\n",
      "Epoch 150/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7388\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5ad0256-2cde-477c-b075-7ee6259e2f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5745 - accuracy: 0.7331\n",
      "Loss: 0.5745089650154114, Accuracy: 0.7330612540245056\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6346232f-f0de-495e-8a0d-5feec87b1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A little better, but not by much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafba8f-8b51-42eb-b035-d85ef17fce78",
   "metadata": {},
   "source": [
    "## Optimization #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d6fb167-0ebd-4d50-a9a0-a5827d9eb38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 24)                1104      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 2,929\n",
      "Trainable params: 2,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "######################## Add some units per layer, add a hidden layer, and change activation to relu #####################################\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"tanh\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd6b7fe9-5a0c-411a-bfb3-37af6e9af7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6eca48b3-5e24-44cc-975b-966faf7e0e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5716 - accuracy: 0.7197\n",
      "Epoch 2/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5541 - accuracy: 0.7287\n",
      "Epoch 3/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5505 - accuracy: 0.7299\n",
      "Epoch 4/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5494 - accuracy: 0.7335\n",
      "Epoch 5/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5477 - accuracy: 0.7326\n",
      "Epoch 6/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.7332\n",
      "Epoch 7/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7320\n",
      "Epoch 8/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7337\n",
      "Epoch 9/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7338\n",
      "Epoch 10/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7331\n",
      "Epoch 11/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7348\n",
      "Epoch 12/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7352\n",
      "Epoch 13/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7360\n",
      "Epoch 14/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5430 - accuracy: 0.7343\n",
      "Epoch 15/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7358\n",
      "Epoch 16/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7354\n",
      "Epoch 17/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7362\n",
      "Epoch 18/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.7357\n",
      "Epoch 19/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5413 - accuracy: 0.7360\n",
      "Epoch 20/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5413 - accuracy: 0.7363\n",
      "Epoch 21/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7350\n",
      "Epoch 22/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7371\n",
      "Epoch 23/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7361: 0s - loss: 0.5406 - accuracy: \n",
      "Epoch 24/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7372\n",
      "Epoch 25/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7367\n",
      "Epoch 26/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7366\n",
      "Epoch 27/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7367\n",
      "Epoch 28/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7376\n",
      "Epoch 29/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7385\n",
      "Epoch 30/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7372\n",
      "Epoch 31/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7383\n",
      "Epoch 32/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7383\n",
      "Epoch 33/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7376\n",
      "Epoch 34/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7383\n",
      "Epoch 35/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7372\n",
      "Epoch 36/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.7377\n",
      "Epoch 37/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7372\n",
      "Epoch 38/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.7371: 0s - loss: 0.5345 \n",
      "Epoch 39/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7384\n",
      "Epoch 40/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7388\n",
      "Epoch 41/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7371\n",
      "Epoch 42/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7392\n",
      "Epoch 43/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7390\n",
      "Epoch 44/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7395\n",
      "Epoch 45/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7383\n",
      "Epoch 46/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7384\n",
      "Epoch 47/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7378\n",
      "Epoch 48/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7395\n",
      "Epoch 49/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7391\n",
      "Epoch 50/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7382\n",
      "Epoch 51/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7389\n",
      "Epoch 52/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7396\n",
      "Epoch 53/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7384\n",
      "Epoch 54/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7387\n",
      "Epoch 55/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7397\n",
      "Epoch 56/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7396\n",
      "Epoch 57/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7386\n",
      "Epoch 58/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7386\n",
      "Epoch 59/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7395\n",
      "Epoch 60/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5354 - accuracy: 0.7380\n",
      "Epoch 61/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5347 - accuracy: 0.7385\n",
      "Epoch 62/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7395\n",
      "Epoch 63/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7389\n",
      "Epoch 64/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7387\n",
      "Epoch 65/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7390\n",
      "Epoch 66/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7399\n",
      "Epoch 67/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7397\n",
      "Epoch 68/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7390\n",
      "Epoch 69/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7388\n",
      "Epoch 70/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7406\n",
      "Epoch 71/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7401\n",
      "Epoch 72/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7397\n",
      "Epoch 73/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7398\n",
      "Epoch 74/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7389\n",
      "Epoch 75/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7404: 0s - loss: 0\n",
      "Epoch 76/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7392\n",
      "Epoch 77/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7402\n",
      "Epoch 78/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7398\n",
      "Epoch 79/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7400\n",
      "Epoch 80/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7397\n",
      "Epoch 81/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7396\n",
      "Epoch 82/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7401\n",
      "Epoch 83/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7406\n",
      "Epoch 84/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7395\n",
      "Epoch 85/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7395\n",
      "Epoch 86/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7399\n",
      "Epoch 87/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7404\n",
      "Epoch 88/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7400\n",
      "Epoch 89/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5326 - accuracy: 0.7396\n",
      "Epoch 90/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7392\n",
      "Epoch 91/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7400\n",
      "Epoch 92/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7406\n",
      "Epoch 93/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7401\n",
      "Epoch 94/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7404\n",
      "Epoch 95/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7404\n",
      "Epoch 96/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7410\n",
      "Epoch 97/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7407\n",
      "Epoch 98/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.7406\n",
      "Epoch 99/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7407\n",
      "Epoch 100/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7404\n",
      "Epoch 101/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7398\n",
      "Epoch 102/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7406\n",
      "Epoch 103/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7396\n",
      "Epoch 104/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7404\n",
      "Epoch 105/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.7408\n",
      "Epoch 106/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7404\n",
      "Epoch 107/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7403\n",
      "Epoch 108/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7411: 0s - loss: 0.5314 - accu\n",
      "Epoch 109/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7410\n",
      "Epoch 110/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7408\n",
      "Epoch 111/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7414\n",
      "Epoch 112/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7414\n",
      "Epoch 113/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7411\n",
      "Epoch 114/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7400\n",
      "Epoch 115/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7414\n",
      "Epoch 116/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7406\n",
      "Epoch 117/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7419\n",
      "Epoch 118/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7411\n",
      "Epoch 119/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7405\n",
      "Epoch 120/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7411\n",
      "Epoch 121/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7410\n",
      "Epoch 122/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7407\n",
      "Epoch 123/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7415\n",
      "Epoch 124/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7404\n",
      "Epoch 125/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7406\n",
      "Epoch 126/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7413\n",
      "Epoch 127/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7414\n",
      "Epoch 128/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7404\n",
      "Epoch 129/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7414\n",
      "Epoch 130/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7418\n",
      "Epoch 131/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7408\n",
      "Epoch 132/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7403\n",
      "Epoch 133/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7416\n",
      "Epoch 134/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7413\n",
      "Epoch 135/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7409\n",
      "Epoch 136/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7419\n",
      "Epoch 137/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7415\n",
      "Epoch 138/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7407\n",
      "Epoch 139/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7414\n",
      "Epoch 140/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7415\n",
      "Epoch 141/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7418\n",
      "Epoch 142/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7411\n",
      "Epoch 143/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7416\n",
      "Epoch 144/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7406\n",
      "Epoch 145/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7412\n",
      "Epoch 146/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7420\n",
      "Epoch 147/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7414\n",
      "Epoch 148/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7405\n",
      "Epoch 149/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7411\n",
      "Epoch 150/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7417\n",
      "Epoch 151/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7415\n",
      "Epoch 152/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7417\n",
      "Epoch 153/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7413\n",
      "Epoch 154/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7413\n",
      "Epoch 155/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7418\n",
      "Epoch 156/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7412\n",
      "Epoch 157/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7405\n",
      "Epoch 158/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7413\n",
      "Epoch 159/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7417\n",
      "Epoch 160/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7410\n",
      "Epoch 161/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7408\n",
      "Epoch 162/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7416\n",
      "Epoch 163/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7412\n",
      "Epoch 164/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7412\n",
      "Epoch 165/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7413\n",
      "Epoch 166/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7414\n",
      "Epoch 167/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7414\n",
      "Epoch 168/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7419\n",
      "Epoch 169/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7414\n",
      "Epoch 170/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7410\n",
      "Epoch 171/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7409\n",
      "Epoch 172/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7419\n",
      "Epoch 173/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7416\n",
      "Epoch 174/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7414\n",
      "Epoch 175/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7407\n",
      "Epoch 176/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7417\n",
      "Epoch 177/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7411\n",
      "Epoch 178/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7414\n",
      "Epoch 179/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7421\n",
      "Epoch 180/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7420\n",
      "Epoch 181/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7412: 0s - loss: 0.5301 - accuracy: \n",
      "Epoch 182/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7411\n",
      "Epoch 183/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7416\n",
      "Epoch 184/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7417\n",
      "Epoch 185/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7419\n",
      "Epoch 186/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7409\n",
      "Epoch 187/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7411\n",
      "Epoch 188/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7416\n",
      "Epoch 189/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7418\n",
      "Epoch 190/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7412\n",
      "Epoch 191/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7424\n",
      "Epoch 192/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7422\n",
      "Epoch 193/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7413\n",
      "Epoch 194/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7413\n",
      "Epoch 195/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7414\n",
      "Epoch 196/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7411\n",
      "Epoch 197/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7420\n",
      "Epoch 198/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7418\n",
      "Epoch 199/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7421\n",
      "Epoch 200/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7413\n",
      "Epoch 201/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7418\n",
      "Epoch 202/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7416\n",
      "Epoch 203/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7414\n",
      "Epoch 204/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7425: 0s -\n",
      "Epoch 205/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5298 - accuracy: 0.7407\n",
      "Epoch 206/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5295 - accuracy: 0.7415\n",
      "Epoch 207/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5300 - accuracy: 0.7416\n",
      "Epoch 208/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5298 - accuracy: 0.7413: 0s -\n",
      "Epoch 209/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5291 - accuracy: 0.7416\n",
      "Epoch 210/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5293 - accuracy: 0.7416\n",
      "Epoch 211/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5296 - accuracy: 0.7417\n",
      "Epoch 212/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7420\n",
      "Epoch 213/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5293 - accuracy: 0.7416\n",
      "Epoch 214/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5298 - accuracy: 0.7411\n",
      "Epoch 215/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5299 - accuracy: 0.7423: 0s - loss: 0.5306 - accuracy: \n",
      "Epoch 216/250\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5294 - accuracy: 0.7421\n",
      "Epoch 217/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7419\n",
      "Epoch 218/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7417\n",
      "Epoch 219/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.7412\n",
      "Epoch 220/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7421\n",
      "Epoch 221/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7419\n",
      "Epoch 222/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7421\n",
      "Epoch 223/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7418\n",
      "Epoch 224/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7421\n",
      "Epoch 225/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7419\n",
      "Epoch 226/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7409\n",
      "Epoch 227/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7424\n",
      "Epoch 228/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7417\n",
      "Epoch 229/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7413\n",
      "Epoch 230/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7420\n",
      "Epoch 231/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7414\n",
      "Epoch 232/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7419\n",
      "Epoch 233/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.7421\n",
      "Epoch 234/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7415\n",
      "Epoch 235/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7418\n",
      "Epoch 236/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7417\n",
      "Epoch 237/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7421\n",
      "Epoch 238/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.7416\n",
      "Epoch 239/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7418\n",
      "Epoch 240/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7418\n",
      "Epoch 241/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7416\n",
      "Epoch 242/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7412\n",
      "Epoch 243/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.7420\n",
      "Epoch 244/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7421\n",
      "Epoch 245/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7414\n",
      "Epoch 246/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5288 - accuracy: 0.7422\n",
      "Epoch 247/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5286 - accuracy: 0.7418\n",
      "Epoch 248/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7414\n",
      "Epoch 249/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7422\n",
      "Epoch 250/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5287 - accuracy: 0.7414\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bf16d3d4-2e7d-42d4-9057-759fa64f6b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5844 - accuracy: 0.7259\n",
      "Loss: 0.5843797326087952, Accuracy: 0.7259474992752075\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2333e048-b9ec-4c26-a049-a017d3301a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not sure where this accuracy test is getting its accuracy from but the epochs managed a steady 74% accuracy which is a little better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e853e9d7-ac2d-49f5-965e-575b150855d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc15647-fbac-48ab-a0b8-e2b7e7bdda0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
