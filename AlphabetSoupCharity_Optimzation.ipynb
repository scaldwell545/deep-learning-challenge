{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13cb713-131a-4a35-bd86-f0b7257d2ab6",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e592d0-01d4-4303-87a7-ad9e97133a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2815f74-a870-46f8-8607-ed307a7e6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f5ba7de-6e47-4b76-99bb-0256e48f4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns = ['EIN', 'NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4369d2f4-b5de-4794-84f8-81e791da34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_type_bins = application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e193d605-0dea-433d-bedc-a93ef3b15084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "#  YOUR CODE GOES HERE\n",
    "\n",
    "#################### Changing bins to include values with over 100 occurrences instead of 500 ####################\n",
    "application_types_to_replace = []\n",
    "cutoff_val = 100\n",
    "for index, val in application_type_bins.items():\n",
    "    if val <= cutoff_val:\n",
    "        application_types_to_replace.append(index)\n",
    "        \n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5107f3eb-b67f-46c1-bd3d-2205c6e4e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_bins = application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2962e6-1916-436d-bf17-864892147954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "\n",
    "#################### Changing bins to include values with over 700 occurrences instead of 1000 ####################\n",
    "classifications_to_replace = []\n",
    "cutoff_val = 700\n",
    "for index, val in classification_bins.items():\n",
    "    if val <= cutoff_val:\n",
    "        classifications_to_replace.append(index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82089139-e9d5-43c7-adc7-574d17016d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "dummies_appilcation_df = pd.get_dummies(application_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bd3d73-aff1-4293-b178-b2e808de1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = dummies_appilcation_df.IS_SUCCESSFUL.values\n",
    "X = dummies_appilcation_df.drop(columns = 'IS_SUCCESSFUL').values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f55c8e-b316-4bd9-974e-176ad47d7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8526bff-0766-492a-a825-4571f574dba2",
   "metadata": {},
   "source": [
    "## Optimization #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c53f781-dd67-4286-afb4-cf27d70e1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 368       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 521\n",
      "Trainable params: 521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "######################## Remove some units per layer, add a hidden layer, and change activation to tanh #####################################\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=8, activation=\"tanh\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=8, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=8, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1e82fc-7a64-46d2-b979-def324bae2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca76249-44c8-4781-b891-d4e04ce498b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "804/804 [==============================] - 3s 2ms/step - loss: 0.5858 - accuracy: 0.7085\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5626 - accuracy: 0.7264\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5583 - accuracy: 0.7284\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5556 - accuracy: 0.7301\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5539 - accuracy: 0.7306\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5532 - accuracy: 0.7302\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5524 - accuracy: 0.7298\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5518 - accuracy: 0.7302\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5508 - accuracy: 0.7312: \n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7313\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7304\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7315\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5493 - accuracy: 0.7321\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.7310\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5486 - accuracy: 0.7314\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.7305\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5480 - accuracy: 0.7312\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7325\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5477 - accuracy: 0.7311\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7314\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.7321\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5471 - accuracy: 0.7323\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.7311\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7304\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7317\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.7316\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7317\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.7307\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7321\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7310\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7327\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7314\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5456 - accuracy: 0.7318\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7327\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7307\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7324\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7314\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7311\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7310\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7317\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7328\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7318\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7322\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7315\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7324\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7319\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7319\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5442 - accuracy: 0.7318\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.7329\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7330\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ffcb142-b869-470f-9ed7-4a8951dc8061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5525 - accuracy: 0.7262\n",
      "Loss: 0.5524606704711914, Accuracy: 0.7261807322502136\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8981c66-0e26-48b2-9b5d-d91747b36c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Slightly better than our attempt before optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335337a-af62-4d62-bd3f-cec79d724d6a",
   "metadata": {},
   "source": [
    "## Optimization #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc47f912-4f53-4e02-99e7-e4abc58a38c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 24)                1104      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,793\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "######################## Add some units per layer, add a hidden layer, and change activation to relu #####################################\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=24, activation=\"relu\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f82f5392-92ea-4ea7-9d06-73f62a2b0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e371ba2d-7064-43e1-bd81-0b56dc07f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5791 - accuracy: 0.7113\n",
      "Epoch 2/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5550 - accuracy: 0.7278\n",
      "Epoch 3/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5530 - accuracy: 0.7290\n",
      "Epoch 4/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5507 - accuracy: 0.7314\n",
      "Epoch 5/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5503 - accuracy: 0.7302\n",
      "Epoch 6/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7307\n",
      "Epoch 7/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5482 - accuracy: 0.7306\n",
      "Epoch 8/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5473 - accuracy: 0.7321\n",
      "Epoch 9/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5468 - accuracy: 0.7331\n",
      "Epoch 10/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7334\n",
      "Epoch 11/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5455 - accuracy: 0.7336: 0s - loss:\n",
      "Epoch 12/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.7335\n",
      "Epoch 13/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5452 - accuracy: 0.7347\n",
      "Epoch 14/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7327\n",
      "Epoch 15/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5437 - accuracy: 0.7347\n",
      "Epoch 16/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5446 - accuracy: 0.7341\n",
      "Epoch 17/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7341\n",
      "Epoch 18/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7341\n",
      "Epoch 19/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7346\n",
      "Epoch 20/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5428 - accuracy: 0.7338\n",
      "Epoch 21/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7346\n",
      "Epoch 22/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7353\n",
      "Epoch 23/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5427 - accuracy: 0.7335\n",
      "Epoch 24/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7357\n",
      "Epoch 25/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7351\n",
      "Epoch 26/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7362\n",
      "Epoch 27/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7353: 0s - loss: 0\n",
      "Epoch 28/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7355\n",
      "Epoch 29/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5412 - accuracy: 0.7350\n",
      "Epoch 30/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7356\n",
      "Epoch 31/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5407 - accuracy: 0.7356\n",
      "Epoch 32/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5407 - accuracy: 0.7364\n",
      "Epoch 33/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7359\n",
      "Epoch 34/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5407 - accuracy: 0.7360\n",
      "Epoch 35/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7362\n",
      "Epoch 36/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7363\n",
      "Epoch 37/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7346\n",
      "Epoch 38/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7353\n",
      "Epoch 39/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5396 - accuracy: 0.7364: 0s - los\n",
      "Epoch 40/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.7362\n",
      "Epoch 41/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.7359\n",
      "Epoch 42/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7364\n",
      "Epoch 43/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7364\n",
      "Epoch 44/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5398 - accuracy: 0.7361\n",
      "Epoch 45/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.7372\n",
      "Epoch 46/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7355\n",
      "Epoch 47/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.7380\n",
      "Epoch 48/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7383\n",
      "Epoch 49/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7368\n",
      "Epoch 50/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7367\n",
      "Epoch 51/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7376\n",
      "Epoch 52/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7369\n",
      "Epoch 53/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7373\n",
      "Epoch 54/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7375\n",
      "Epoch 55/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7367\n",
      "Epoch 56/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7369\n",
      "Epoch 57/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7371\n",
      "Epoch 58/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7385\n",
      "Epoch 59/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7372\n",
      "Epoch 60/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7373\n",
      "Epoch 61/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7382: 0s -\n",
      "Epoch 62/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7386\n",
      "Epoch 63/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7369\n",
      "Epoch 64/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7373\n",
      "Epoch 65/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7371\n",
      "Epoch 66/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7376\n",
      "Epoch 67/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7385\n",
      "Epoch 68/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7386\n",
      "Epoch 69/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7382\n",
      "Epoch 70/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7372\n",
      "Epoch 71/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7373\n",
      "Epoch 72/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7371\n",
      "Epoch 73/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7377\n",
      "Epoch 74/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7363: 0s - loss: 0.5374 - accuracy\n",
      "Epoch 75/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7383\n",
      "Epoch 76/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7381\n",
      "Epoch 77/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7385\n",
      "Epoch 78/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7378\n",
      "Epoch 79/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7378\n",
      "Epoch 80/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7381: 0s - l\n",
      "Epoch 81/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7378\n",
      "Epoch 82/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7384\n",
      "Epoch 83/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7385\n",
      "Epoch 84/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7375\n",
      "Epoch 85/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7386\n",
      "Epoch 86/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7379\n",
      "Epoch 87/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7377\n",
      "Epoch 88/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7383\n",
      "Epoch 89/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7386\n",
      "Epoch 90/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7394\n",
      "Epoch 91/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7388\n",
      "Epoch 92/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7383\n",
      "Epoch 93/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7390\n",
      "Epoch 94/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7395\n",
      "Epoch 95/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7378\n",
      "Epoch 96/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7385\n",
      "Epoch 97/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7388\n",
      "Epoch 98/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7402\n",
      "Epoch 99/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7394\n",
      "Epoch 100/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7386\n",
      "Epoch 101/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7385\n",
      "Epoch 102/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7376\n",
      "Epoch 103/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7386\n",
      "Epoch 104/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7390\n",
      "Epoch 105/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7383\n",
      "Epoch 106/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7386\n",
      "Epoch 107/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7386\n",
      "Epoch 108/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7397\n",
      "Epoch 109/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7397\n",
      "Epoch 110/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7390\n",
      "Epoch 111/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7390\n",
      "Epoch 112/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7385\n",
      "Epoch 113/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7386\n",
      "Epoch 114/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7389\n",
      "Epoch 115/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7390\n",
      "Epoch 116/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7393: 0s - loss: 0\n",
      "Epoch 117/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7383\n",
      "Epoch 118/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7384\n",
      "Epoch 119/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7391\n",
      "Epoch 120/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7394\n",
      "Epoch 121/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7383\n",
      "Epoch 122/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7382\n",
      "Epoch 123/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7395\n",
      "Epoch 124/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7383: 0s - loss: 0.5339 - accuracy: 0.\n",
      "Epoch 125/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7393\n",
      "Epoch 126/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7387\n",
      "Epoch 127/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7392\n",
      "Epoch 128/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7390\n",
      "Epoch 129/150\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7381\n",
      "Epoch 130/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7390\n",
      "Epoch 131/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7388\n",
      "Epoch 132/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7390\n",
      "Epoch 133/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7384\n",
      "Epoch 134/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7387\n",
      "Epoch 135/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7388\n",
      "Epoch 136/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7391\n",
      "Epoch 137/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7399\n",
      "Epoch 138/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7383\n",
      "Epoch 139/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7404\n",
      "Epoch 140/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7392\n",
      "Epoch 141/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7398\n",
      "Epoch 142/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7375\n",
      "Epoch 143/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7395\n",
      "Epoch 144/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7407\n",
      "Epoch 145/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7404\n",
      "Epoch 146/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7402\n",
      "Epoch 147/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7384\n",
      "Epoch 148/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7394\n",
      "Epoch 149/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7399\n",
      "Epoch 150/150\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7388\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5ad0256-2cde-477c-b075-7ee6259e2f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5590 - accuracy: 0.7278\n",
      "Loss: 0.5590168833732605, Accuracy: 0.7278134226799011\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6346232f-f0de-495e-8a0d-5feec87b1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A little better, but not by much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafba8f-8b51-42eb-b035-d85ef17fce78",
   "metadata": {},
   "source": [
    "## Optimization #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3d6fb167-0ebd-4d50-a9a0-a5827d9eb38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 40)                1840      \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 28)                1148      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 1)                 29        \n",
      "=================================================================\n",
      "Total params: 3,829\n",
      "Trainable params: 3,829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "######################## Add some units per layer, add a hidden layer, and change activation to relu #####################################\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=40, activation=\"sigmoid\", input_dim=45))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=28, activation=\"sigmoid\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=28, activation=\"sigmoid\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=28, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3e21703d-3ce1-44d0-8aea-098e3136c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adamax(learning_rate=0.008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dd6b7fe9-5a0c-411a-bfb3-37af6e9af7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer = optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6eca48b3-5e24-44cc-975b-966faf7e0e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5835 - accuracy: 0.7155\n",
      "Epoch 2/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5633 - accuracy: 0.7268\n",
      "Epoch 3/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5583 - accuracy: 0.7283\n",
      "Epoch 4/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5551 - accuracy: 0.7295\n",
      "Epoch 5/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5538 - accuracy: 0.7295\n",
      "Epoch 6/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5526 - accuracy: 0.7294\n",
      "Epoch 7/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5510 - accuracy: 0.7302\n",
      "Epoch 8/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.7300\n",
      "Epoch 9/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.7312\n",
      "Epoch 10/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.7317\n",
      "Epoch 11/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5476 - accuracy: 0.7304\n",
      "Epoch 12/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7326\n",
      "Epoch 13/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5479 - accuracy: 0.7321\n",
      "Epoch 14/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7328\n",
      "Epoch 15/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5461 - accuracy: 0.7313\n",
      "Epoch 16/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5458 - accuracy: 0.7330\n",
      "Epoch 17/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7327\n",
      "Epoch 18/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7325\n",
      "Epoch 19/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7325\n",
      "Epoch 20/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5441 - accuracy: 0.7322\n",
      "Epoch 21/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5443 - accuracy: 0.7330\n",
      "Epoch 22/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.7343\n",
      "Epoch 23/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5435 - accuracy: 0.7338\n",
      "Epoch 24/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7335\n",
      "Epoch 25/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.7337\n",
      "Epoch 26/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7354\n",
      "Epoch 27/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.7345\n",
      "Epoch 28/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7346\n",
      "Epoch 29/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7348\n",
      "Epoch 30/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5412 - accuracy: 0.7349\n",
      "Epoch 31/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7352\n",
      "Epoch 32/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7357\n",
      "Epoch 33/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7353\n",
      "Epoch 34/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5402 - accuracy: 0.7352\n",
      "Epoch 35/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5400 - accuracy: 0.7364\n",
      "Epoch 36/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.7352\n",
      "Epoch 37/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7357\n",
      "Epoch 38/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7355\n",
      "Epoch 39/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5391 - accuracy: 0.7358\n",
      "Epoch 40/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7360\n",
      "Epoch 41/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7363\n",
      "Epoch 42/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5380 - accuracy: 0.7360\n",
      "Epoch 43/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7362\n",
      "Epoch 44/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5383 - accuracy: 0.7365\n",
      "Epoch 45/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7371\n",
      "Epoch 46/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7369\n",
      "Epoch 47/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5375 - accuracy: 0.7370\n",
      "Epoch 48/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7366\n",
      "Epoch 49/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7365\n",
      "Epoch 50/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7373\n",
      "Epoch 51/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7356\n",
      "Epoch 52/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7369\n",
      "Epoch 53/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7361\n",
      "Epoch 54/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7369\n",
      "Epoch 55/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7374\n",
      "Epoch 56/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7376\n",
      "Epoch 57/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7372\n",
      "Epoch 58/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7366\n",
      "Epoch 59/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7378\n",
      "Epoch 60/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7367\n",
      "Epoch 61/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.7378\n",
      "Epoch 62/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7377\n",
      "Epoch 63/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7378\n",
      "Epoch 64/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7383\n",
      "Epoch 65/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7378\n",
      "Epoch 66/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7374\n",
      "Epoch 67/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7378\n",
      "Epoch 68/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7380: 0s - loss:\n",
      "Epoch 69/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7393\n",
      "Epoch 70/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7386\n",
      "Epoch 71/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7387\n",
      "Epoch 72/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7381\n",
      "Epoch 73/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7379\n",
      "Epoch 74/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7378: 0s - loss:\n",
      "Epoch 75/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7381: 0s\n",
      "Epoch 76/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7375\n",
      "Epoch 77/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7386\n",
      "Epoch 78/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7385\n",
      "Epoch 79/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7398\n",
      "Epoch 80/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7388\n",
      "Epoch 81/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7391\n",
      "Epoch 82/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7380\n",
      "Epoch 83/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7376\n",
      "Epoch 84/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7388\n",
      "Epoch 85/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7384\n",
      "Epoch 86/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7394\n",
      "Epoch 87/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7400\n",
      "Epoch 88/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7377\n",
      "Epoch 89/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7404\n",
      "Epoch 90/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7385: 0s - loss: 0.5336 - accuracy: 0.\n",
      "Epoch 91/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7391\n",
      "Epoch 92/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7390\n",
      "Epoch 93/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7393\n",
      "Epoch 94/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7390\n",
      "Epoch 95/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7382\n",
      "Epoch 96/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7398\n",
      "Epoch 97/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7401\n",
      "Epoch 98/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5330 - accuracy: 0.7393\n",
      "Epoch 99/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7392: 0s - loss: 0.5345 - accuracy: \n",
      "Epoch 100/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7395\n",
      "Epoch 101/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7385\n",
      "Epoch 102/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7401\n",
      "Epoch 103/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7392\n",
      "Epoch 104/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7397\n",
      "Epoch 105/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7380\n",
      "Epoch 106/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7399\n",
      "Epoch 107/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7402\n",
      "Epoch 108/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5326 - accuracy: 0.7392: 0s - los\n",
      "Epoch 109/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7397\n",
      "Epoch 110/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7397\n",
      "Epoch 111/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7392\n",
      "Epoch 112/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7391\n",
      "Epoch 113/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7390\n",
      "Epoch 114/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7392\n",
      "Epoch 115/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7404\n",
      "Epoch 116/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7399\n",
      "Epoch 117/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7386\n",
      "Epoch 118/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7400\n",
      "Epoch 119/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7395\n",
      "Epoch 120/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.7394\n",
      "Epoch 121/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7395\n",
      "Epoch 122/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7397\n",
      "Epoch 123/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.7386\n",
      "Epoch 124/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7400\n",
      "Epoch 125/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7402\n",
      "Epoch 126/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7398\n",
      "Epoch 127/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7399\n",
      "Epoch 128/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7402\n",
      "Epoch 129/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7392\n",
      "Epoch 130/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7407\n",
      "Epoch 131/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7398\n",
      "Epoch 132/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5317 - accuracy: 0.7398\n",
      "Epoch 133/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7390: 0s -\n",
      "Epoch 134/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.7400\n",
      "Epoch 135/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7407\n",
      "Epoch 136/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7403\n",
      "Epoch 137/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7406\n",
      "Epoch 138/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7404\n",
      "Epoch 139/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7400\n",
      "Epoch 140/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7410\n",
      "Epoch 141/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7398\n",
      "Epoch 142/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7404\n",
      "Epoch 143/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7407\n",
      "Epoch 144/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5315 - accuracy: 0.7403\n",
      "Epoch 145/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7399\n",
      "Epoch 146/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7409\n",
      "Epoch 147/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7409\n",
      "Epoch 148/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7402\n",
      "Epoch 149/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.7407\n",
      "Epoch 150/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.7406\n",
      "Epoch 151/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7416\n",
      "Epoch 152/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7408\n",
      "Epoch 153/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7412\n",
      "Epoch 154/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7404\n",
      "Epoch 155/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7405\n",
      "Epoch 156/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7404\n",
      "Epoch 157/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.7406\n",
      "Epoch 158/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7407: 0s -\n",
      "Epoch 159/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7392\n",
      "Epoch 160/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7402\n",
      "Epoch 161/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5310 - accuracy: 0.7405\n",
      "Epoch 162/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7414\n",
      "Epoch 163/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7403\n",
      "Epoch 164/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7407\n",
      "Epoch 165/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7414: 0s - loss: 0\n",
      "Epoch 166/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7413\n",
      "Epoch 167/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7411\n",
      "Epoch 168/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7411\n",
      "Epoch 169/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7418\n",
      "Epoch 170/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7405\n",
      "Epoch 171/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.7400\n",
      "Epoch 172/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5306 - accuracy: 0.7408\n",
      "Epoch 173/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7404\n",
      "Epoch 174/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7409\n",
      "Epoch 175/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7410\n",
      "Epoch 176/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7411\n",
      "Epoch 177/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7408\n",
      "Epoch 178/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7415\n",
      "Epoch 179/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7412\n",
      "Epoch 180/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.7407\n",
      "Epoch 181/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7414\n",
      "Epoch 182/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7414\n",
      "Epoch 183/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7409\n",
      "Epoch 184/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7413\n",
      "Epoch 185/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7413\n",
      "Epoch 186/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7416\n",
      "Epoch 187/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7405\n",
      "Epoch 188/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7420\n",
      "Epoch 189/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7414\n",
      "Epoch 190/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.7412\n",
      "Epoch 191/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7409\n",
      "Epoch 192/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7414\n",
      "Epoch 193/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7414\n",
      "Epoch 194/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7403\n",
      "Epoch 195/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7410\n",
      "Epoch 196/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7409\n",
      "Epoch 197/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.7406\n",
      "Epoch 198/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7406\n",
      "Epoch 199/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7411\n",
      "Epoch 200/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7409\n",
      "Epoch 201/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7407\n",
      "Epoch 202/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5301 - accuracy: 0.7412\n",
      "Epoch 203/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7414\n",
      "Epoch 204/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.7412\n",
      "Epoch 205/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7412\n",
      "Epoch 206/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7411\n",
      "Epoch 207/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7413\n",
      "Epoch 208/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7411\n",
      "Epoch 209/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7408\n",
      "Epoch 210/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7419\n",
      "Epoch 211/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7419\n",
      "Epoch 212/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7404\n",
      "Epoch 213/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7413\n",
      "Epoch 214/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7416\n",
      "Epoch 215/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7403\n",
      "Epoch 216/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7409\n",
      "Epoch 217/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7419\n",
      "Epoch 218/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7414\n",
      "Epoch 219/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7411: 0s -\n",
      "Epoch 220/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7408\n",
      "Epoch 221/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7418\n",
      "Epoch 222/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7415\n",
      "Epoch 223/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7413\n",
      "Epoch 224/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5296 - accuracy: 0.7415\n",
      "Epoch 225/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.7418\n",
      "Epoch 226/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7416\n",
      "Epoch 227/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7409\n",
      "Epoch 228/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7423\n",
      "Epoch 229/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7413\n",
      "Epoch 230/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7413\n",
      "Epoch 231/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7413\n",
      "Epoch 232/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7419\n",
      "Epoch 233/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7411\n",
      "Epoch 234/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7418\n",
      "Epoch 235/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7424\n",
      "Epoch 236/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7418\n",
      "Epoch 237/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7419\n",
      "Epoch 238/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.7416\n",
      "Epoch 239/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7419\n",
      "Epoch 240/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.7419\n",
      "Epoch 241/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7418\n",
      "Epoch 242/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.7412\n",
      "Epoch 243/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7424\n",
      "Epoch 244/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7414\n",
      "Epoch 245/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7415: 0s\n",
      "Epoch 246/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7414\n",
      "Epoch 247/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7410\n",
      "Epoch 248/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5293 - accuracy: 0.7415\n",
      "Epoch 249/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7421\n",
      "Epoch 250/250\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5291 - accuracy: 0.7415\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bf16d3d4-2e7d-42d4-9057-759fa64f6b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 1s 1ms/step - loss: 0.5788 - accuracy: 0.7313\n",
      "Loss: 0.5787718892097473, Accuracy: 0.7313119769096375\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2333e048-b9ec-4c26-a049-a017d3301a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not sure where this accuracy test is getting its accuracy from but the epochs managed a steady 74.15% accuracy which is a little better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e853e9d7-ac2d-49f5-965e-575b150855d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0cc15647-fbac-48ab-a0b8-e2b7e7bdda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save('Models/alphabetSoupCharity_Optimization.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb46dee-66fc-42c4-a0f8-6d69a41a5d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
